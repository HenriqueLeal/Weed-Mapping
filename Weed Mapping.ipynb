{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](http://www.lapix.ufsc.br/wp-content/uploads/2019/06/VC-lapix.png)\n",
    "\n",
    "# Weed Mapping in Aerial Images through Identification and Segmentation of Crop Rows and Weeds\n",
    "\n",
    "Notebook for Weed Mapping in Aerial Images through Identification and Segmentation of Crop Rows and Weeds using Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1LAyKA2DM7QUMSxXn_VSW-z1PY2OLbjyX\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Python-v.3.7-green.png\" alt=\"Python Version\" title=\"Python Version\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations and general instructions\n",
    "\n",
    "Networks for semantic segmentation classify objects into images and are able to associate individual pixels of the images with the object class they represent, performing in practice a segmentation of the image according to the semantics of the object to which each individual pixel is associated.\n",
    "\n",
    "In this work we use our own dataset containing RGB images of a sugarcane plantation applied to four models of CNN deployed in this repository that was adapted from the, already deprecated, code at: https://github.com/GeorgeSeif/Semantic-Segmentation-Suite by George Seif. This notebook assumes that you are using Google Colab. If not, please see the instructions of installation and usage described along our repository at: \n",
    " - https://github.com/awangenh/Weed-Mapping or\n",
    " - https://codigos.ufsc.br/lapix/Weed-Mapping\n",
    "\n",
    "We used the models: **SegNet, UNet, FRRN and PSPNet**. Some ground truths and respective results are shown in the first figure of the repo.\n",
    "\n",
    "Everything you need to know about training, testing and making predictions on your dataset  are explained in this notebook and in this repository depending on which platform you are using. To use Google Colab you don't need to import the Tensorflow Framework.\n",
    "\n",
    "## Setting you Dataset\n",
    "The first thing you need to acomplish is to organize the structure of the folders of your data as explained in the \"**Usage**\"\" part of the repository.\n",
    "Do not forget to edit the text file \"*class_dict.csv*\" specific for your information.\n",
    "\n",
    "Observe that our dataset was stored in a folder calle *Dataset_ArticleBackground*. The code below reflects this. You will have to adapt the code to your environment.\n",
    "\n",
    "After that, you just need to upload the content to the Drive.\n",
    "\n",
    "## Mounting your data:\n",
    "Next you need to define the place where all the scripts available in the repository and also your dataset are stored:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the processor\n",
    "\n",
    "To use the GPU available go to:\n",
    "\n",
    "Edit >> Notebook settings >> choose the Runtime type and GPU as Hardware accelerator.\n",
    "\n",
    "The code below is for you to check the version of the GPU being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/bin/nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train the model\n",
    "\n",
    "Access the directory where you mounted your project and call the script to run the training of the model:\n",
    "\n",
    "In our work is the **train_balancing_metrics.py**\n",
    "\n",
    "Is also needed to give some parameters. We used the following:\n",
    "\n",
    "\n",
    "\n",
    "*   num_epochs = 200\n",
    "\n",
    "*   dataset = \"The folder where our dataset is located\"\n",
    "\n",
    "* num_val_images = 44, the number of images in our validation set\n",
    "\n",
    "* h_flip and v_flip = True, to use operations fo data augmentation\n",
    "\n",
    "* model = \"FRRN-B\", or any other model choosen\n",
    "\n",
    "* batch_size = 3 (worked for us!)\n",
    "\n",
    "* continue_training = False, to start training from the begining\n",
    "\n",
    "In the repository mentioned above, there is an explanation for all the parameters that can be used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/My\\ Drive/DeepLearning/Semantic-Segmentation-Suite-master/\n",
    "\n",
    "!python train_balancing_metrics.py --num_epochs=200 --dataset=\"Dataset_ArticleBackground\" --num_val_images=44 --h_flip=True --v_flip=True --model=\"DeepLabV3\" --batch_size=3 --continue_training=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "\n",
    "Here is the code to test you model over your test set.\n",
    "\n",
    "Call the test script (**test.py**) and pass the parameters\n",
    "\n",
    "The **checkpoint_path** is the path where the weights for that trained model are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/My\\ Drive/DeepLearning/Semantic-Segmentation-Suite-master/\n",
    "\n",
    "!python test.py --dataset=\"Dataset_ArticleBackground\" --model=\"FRRN-B\" --checkpoint_path='checkpoints/latest_model_FRRN-B_Dataset_ArticleBackground.ckpt' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction\n",
    "\n",
    "This code is used when you want to make a prediction for new single images.\n",
    "\n",
    "Call the **predict.py** with the correct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/My\\ Drive/DeepLearning/Semantic-Segmentation-Suite-master/\n",
    "\n",
    "!python predict.py --dataset=\"Dataset_ArticleBackground\" --model=\"FRRN-B\" --checkpoint_path='checkpoints/latest_model_FRRN-B_Dataset_ArticleBackground.ckpt' --crop_height=512 --crop_width=512 --image=\"Dataset_ArticleBackground/test/115.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner Creative Commons INCoD UFSC](http://www.lapix.ufsc.br/wp-content/uploads/2019/05/cc.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
